# Image Editting

I felt like making a bunch of stuff that you would find in an image
editor. The image shown on the bottom is a randomly generated set of
squares. The image shown on the top is the output of the rendering
(sometimes I make it rotate, others I leave it stationary).

## Cavaets

### No Type Casting

You cannot cast from int to float or float to int. GLSL seems to have
functions to handle that but I have been unable to get them to work
(specifically: `intBitsToFloat`, `uintBitsToFloat`, `floatBitsToInt`,
and `floatBitsToUint`).

### New Vectors

The easy way to make a 3 component vector from a 4 is:

	uniform sampler2D tTexture;
	uniform vec3 color;
	void main() {
		vec4 pixel = texture2D(tTexture, vUv);
		vec3 rgb = vec3( pixel.r, pixel.g, pixel.b );
		// omitted ...
	}

Making a constant vector:

	vec4 opaqueBlack = vec4( 0.0, 0.0, 0.0, 1.0 );

### Color Agreement

The colors passed from THREE.js and DAT.GUI are in the 0-255 range;
therefore, when working with a color passes to a shader you need to
divide it by 255.0.

### Distance Mapping

The distance between 2 n-dimensional vectors (whose components can range
from 0.0 to 1.0) can range between 0.0 and sqrt(n); therefore, if you
need a distance metric to be a color value scale it by dividing by
sqrt(n). For example the distance between 2, 3-dimensional vectors
should be scaled by sqrt(3) (or ~1.7).

### Alpha Values

You can set alpha values in your fragment shader but they will have no
effect unless your shader material has transparency enabled and is
using an appropriate blending equation. I use the following snippet of
code to setup the material:

	// Create the material
	var material = new THREE.ShaderMaterial( {
		uniforms: uniforms,
		vertexShader: document.getElementById( 'vertexShader' ).textContent,
		fragmentShader: document.getElementById( 'fragmentShader' ).textContent,
		transparent: true
	} );

For more control you can change the blending method:

	// Create the material
	var material = new THREE.ShaderMaterial( {
		uniforms: uniforms,
		vertexShader: document.getElementById( 'vertexShader' ).textContent,
		fragmentShader: document.getElementById( 'fragmentShader' ).textContent,
		transparent: true,
		blending: 'NormalBlending',
		blendSrc: 'SrcAlphaFactor',
		blendDst: 'OneFactor'
	} );

You can see an example of the different blending methods at:
http://threejs.org/examples/#webgl_materials_blending_custom

### DAT.GUI

There are some problems with using the uniforms data that gets passed
to THREE.js as a target object for DAT.GUI. I broke the data into 2
parts: the `uniforms` passed to THREE.js and the `parameters` shown by
DAT.GUI. I have to use the `onChange` event of each parameter to update
the uniforms. Below is an example setup for the brightness and contrast
example:

	var uniforms = {
		tTexture: {
			type: 't',
			value: texture
		},
		uBrightness: {
			type: 'f',
			value: 0.0
		},
		uContrast: {
			type: 'f',
			value: 0.0
		}
	};
	var parameters = {
		brightness: uniforms.uBrightness.value,
		contrast: uniforms.uContrast.value
	};

	var gui = new dat.GUI();
	gui.add(parameters, 'brightness').min(-1.0).max(1.0).step(0.01).onChange(function(value){
		uniforms.uBrightness.value = value;
	});
	gui.add(parameters, 'contrast').min(-0.5).max(0.5).step(0.01).onChange(function(value){
		uniforms.uContrast.value = value;
	});

## Vertex Shader

All of the vertex shaders are the same. They convert the vertex from 
3-dimensional space to 2-dimensional space and pass the UV coordinates
to the fragement shaders:

	varying vec2 vUv;
	void main() {
		gl_Position = projectionMatrix * modelViewMatrix * vec4(position,1.0);
		vUv = uv;
	}

The fragment shaders implement the interesting part of the algorithms;
they are based on UV coordinates.

## Fragment Shaders - Single Pixel

### Copy

We'll start with the most basic - a straight copy operation. All we
have to do is read the pixel value from the UV coordinate:

	uniform sampler2D tTexture;
	varying vec2 vUv;
	void main() {
		gl_FragColor = texture2D(tTexture, vUv);
	}

### Invert

Inversion makes black areas white and white areas black. This is
accomplished by subtracting each of the r,g,b pixel values from 1.0 as
shown below:

	uniform sampler2D tTexture;
	varying vec2 vUv;
	void main() {
		vec4 color = texture2D(tTexture, vUv);
		gl_FragColor.r = 1.0 - color.r;
		gl_FragColor.g = 1.0 - color.g;
		gl_FragColor.b = 1.0 - color.b;
		gl_FragColor.a = color.a;
	}

If you're familiar with HTML5's canvas API then you would expect that 
`1.0` to be `255`. WebGL uses color values between 0.0 and 1.0 because
it simplifies the combining of colors.

### Luma (Greyscale)

You can convert a r,g,b value to a greyscale value by a simple formula.
A grey pixel has all of the samle values for r,g,b; therefore, we
compute the luma value for a pixel and set r,g, and b to that value:

	uniform sampler2D tTexture;
	varying vec2 vUv;
	void main() {
		vec4 color = texture2D(tTexture, vUv);
		float luma = 0.30*color.r + 0.59*color.g + 0.11*color.b;
		gl_FragColor.r = luma;
		gl_FragColor.g = luma;
		gl_FragColor.b = luma;
		gl_FragColor.a = color.a;
	}

### Colorization

You can convert an image to greyscale then re-color that image so it
looks like a specific color. To do this you compute the grey level of
each pixel then multiply each channel by the color you want the image
to be:

	uniform sampler2D tTexture;
	uniform vec3 colorize;
	varying vec2 vUv;
	void main() {
		vec4 color = texture2D(tTexture, vUv);
		float luma = 0.05*(0.30*color.r + 0.59*color.g + 0.11*color.b);
		gl_FragColor.r = luma*colorize.r;
		gl_FragColor.g = luma*colorize.g;
		gl_FragColor.b = luma*colorize.b;
		gl_FragColor.a = color.a;
	}

This is one scenario in which having numbers between 0.0 and 1.0 is
better than having numbers between 0 and 255. Imagine a luma of 128
and an r,g,b of 0,2,100; multiplication would yield an r,g,b of
0,256,12800 which is outside of the 0-255 range so we would have to add
an additional division of 255 to get the correct value. With the 0.0 to
1.0 range we would have a luma of 0.5 and r,g,b of 0.0, 0.008, 0.5 and a
final r,g,b of 0.0, 0.004, 0.25 (no additional scaling required).

### RGB Adjust

You can make a image more or less red (or green or blue) by scaling
whichever channel(s) you want to amplify (or remove):

	uniform sampler2D tTexture;
	varying vec2 vUv;
	uniform vec3 uRgbAdjust;
	void main() {
		vec4 color = texture2D(tTexture, vUv);
		gl_FragColor.r = uRgbAdjust.r*color.r;
		gl_FragColor.g = uRgbAdjust.g*color.g;
		gl_FragColor.b = uRgbAdjust.b*color.b;
		gl_FragColor.a = color.a;
	}

### Brightness

You can make an image brighter (more white) by adding a constant to ALL
the r,g,b values. Similarly, you can make it darker by subtracting a
constant from all the r,g,b values:

	uniform sampler2D tTexture;
	uniform float uBrightness;
	varying vec2 vUv;
	void main() {
		vec4 color = texture2D(tTexture, vUv);
		gl_FragColor.r = clamp( color.r+uBrightness, 0.0, 1.0 );
		gl_FragColor.g = clamp( color.g+uBrightness, 0.0, 1.0 );
		gl_FragColor.b = clamp( color.b+uBrightness, 0.0, 1.0 );
		gl_FragColor.a = color.a;
	}

There is a `clamp` function provided in GLSL which forces a number to
stay between a minimum and maximum value. In the above example, I'm
clamping the brightened (or darkened) r,g,b values between 0.0 and 1.0.

### Contrast

You can think of contrast as the spread of the histogram that represents
the distribution of color channel values in the image. The maximum range
of this histogram is 1.0 (ie a pixel with 0.0 red and another with 1.0
red). The minimum range is 0.0 (ie all red pixels have the same red).

We can "push" the color values away from the middle (0.5) to increase
the contrast or "pull" the color values to the middle to decrease the
contrast (ie make it more grey). This means our contrast values are
always between -0.5 and +0.5.

Increasing the contrast is handled separately from decreasing the
contrast. For increasing the contrast: if the value is above the middle
we add the contrast amount to the pixel's channel value; otherwise, we
subtract. Similar logic applies to the decreasing contrast (note that 
the sign of the contrasting value is negative).

The implementation is given below:

	uniform sampler2D tTexture;
	uniform float uContrast;
	varying vec2 vUv;
	void main() {
		vec4 color = texture2D(tTexture, vUv);
		float r = color.r;
		float g = color.g;
		float b = color.b;
		if( uContrast > 0.0 ){
			r = (r > 0.5) ? clamp(r + uContrast, 0.0, 1.0) : clamp(r - uContrast, 0.0, 1.0);
			g = (g > 0.5) ? clamp(g + uContrast, 0.0, 1.0) : clamp(g - uContrast, 0.0, 1.0);
			b = (b > 0.5) ? clamp(b + uContrast, 0.0, 1.0) : clamp(b - uContrast, 0.0, 1.0);
		}
		if( uContrast < 0.0 ){
			r = (r > 0.5) ? clamp(r + uContrast, 0.5, 1.0) : clamp(r - uContrast, 0.0, 0.5);
			g = (g > 0.5) ? clamp(g + uContrast, 0.5, 1.0) : clamp(g - uContrast, 0.0, 0.5);
			b = (b > 0.5) ? clamp(b + uContrast, 0.5, 1.0) : clamp(b - uContrast, 0.0, 0.5);
		}
		gl_FragColor.r = r;
		gl_FragColor.g = g;
		gl_FragColor.b = b;
		gl_FragColor.a = color.a;
	}

### HSV Adjust

Working in the HSV (hue, saturation, value) color space can be easier
than working in the RGB colorspace. The HSV adjustment demo shows how
to convert between RGB and HSV (note: HSV is not the same as HSL). To
make this more re-usable `rgbaToHsva` and `hsvaToRgba` were coded as
separate functions (the `main` function handles applying the
adjustments).

When converting we store the hue in the red channel, the saturation in
the green channel, and the value in the blue channel. Below is the
complete shader:

	vec4 rgbaToHsva( vec4 pixel ){
		vec4 hsva;
		float r = pixel.r;
		float g = pixel.g;
		float b = pixel.b;

		// Is the black/grey/white (ie no color)?
		float rgbMin = min(min(r,g),b);
		float rgbMax = max(max(r,g),b);
		if( rgbMin == rgbMax ){
			hsva.r = 0.0;
			hsva.g = 0.0;
			hsva.b = rgbMin;
			hsva.a = pixel.a;
			return hsva;
		}

		// Its got color
		float d = (r==rgbMin) ? g-b : ((b==rgbMin) ? r-g : b-r);
		float h = (r==rgbMin) ? 3.0 : ((b==rgbMin) ? 1.0 : 5.0);
		float hue = (h - d/(rgbMax - rgbMin));
		float sat = (rgbMax - rgbMin)/rgbMax;
		float val = rgbMax;

		hsva.r = hue/6.0;
		hsva.g = sat;
		hsva.b = val;
		hsva.a = pixel.a;

		return hsva;
	}

	vec4 hsvaToRgba( vec4 pixel ){

		vec4 rgba;

		// hue 0-360, s 0-1, v 0-1
		float h = pixel.r;
		float s = pixel.g;
		float v = pixel.b;

		// If the color is not saturated then it is a shade of
		// grey equal to the value (0.004 ~ 1.0/255.0)
		if( s < 0.004 ) {
			rgba.r = v;
			rgba.g = v;
			rgba.b = v;
			rgba.a = pixel.a;
			return rgba;
		}

		// The HSL colorspace is a rotated cube. It can be projected
		// onto the "chromaticity" plane where it looks like a hexagon.
		// We determine which edge of the hexagon this color is on and
		// assign the computed values to the appropriate r,g,b channels.
		h *= 6.0;
		//int edge = floatBitsToInt( h );
		float edge = floor( h );
		float frac = fract( h );

		// These are the RGB values.
		float r, g ,b;
		float p, q, t;
		p = v * ( 1.0 - s );
		q = v * ( 1.0 - s * frac );
		t = v * ( 1.0 - s * ( 1.0 - frac ) );

		if( edge == 0.0 ){
				r = v;
				g = t;
				b = p;
		}else if( edge == 1.0 ){
				r = q;
				g = v;
				b = p;
		}else if( edge == 2.0 ){
				r = p;
				g = v;
				b = t;
		}else if( edge == 3.0 ){
				r = p;
				g = q;
				b = v;
		}else if( edge == 4.0 ){
				r = t;
				g = p;
				b = v;
		}else{
				r = v;
				g = p;
				b = q;
		}

		rgba.r = r;
		rgba.g = g;
		rgba.b = b;
		rgba.a = pixel.a;
		return rgba;

	}

	uniform sampler2D tTexture;
	uniform float uHue;
	uniform float uSaturation;
	uniform float uValue;
	varying vec2 vUv;
	void main() {
		vec4 pixel = texture2D(tTexture, vUv);
		vec4 hsva = rgbaToHsva( pixel );
		hsva.r = mod( hsva.r + uHue, 1.0 );
		hsva.g = clamp( hsva.g+uSaturation, 0.0, 1.0 );
		hsva.b = clamp( hsva.b+uValue, 0.0, 1.0 );
		gl_FragColor = hsvaToRgba( hsva );
	}

I cannot explain HSV as well as Wikipedia so (if you're curious) take a
look at: https://en.wikipedia.org/wiki/HSL_and_HSV

### Color To Alpha

It can be hard to film at a specific location or in a specific
environment. To combat that problem, movie makers often film infront of
a "green screen." After the filming is completed the green background
is replaced with the appropriate background. To achive that effect:
anything that matches the green color is made transparent. Making that
effect only work with a specific shade of green is boring, so instead, I
made it work with any color. The closer the pixel is to the target color
the more transparent it becomes (ie a 100% match is 100% transparent
while a 50% is only 50% transparent). The implementation is shown below:

	uniform sampler2D tTexture;
	uniform vec3 color;
	varying vec2 vUv;
	void main() {
		vec4 pixel = texture2D(tTexture, vUv);
		vec3 rgb = vec3( pixel.r, pixel.g, pixel.b );

		// We have to normalize the distance from 0-sqrt(3) to 0-1
		gl_FragColor.r = pixel.r;
		gl_FragColor.g = pixel.g;
		gl_FragColor.b = pixel.b;
		gl_FragColor.a = (distance(rgb,color/255.0)/1.73205080756887729352);
	}

### Treshold

Thresholding splits a range of values into 1 of 2 extremes. If the
value is above the threshold: it gets mapped to the max. If the value
is below the threshold it gets mapped to the minimum. GLSL has a built
in `step` function which handles that logic. We can use it to threshold
an image as shown below:

	uniform sampler2D tTexture;
	uniform float uThresholdR;
	uniform float uThresholdG;
	uniform float uThresholdB;
	varying vec2 vUv;
	void main() {
		vec4 pixel = texture2D(tTexture, vUv);
		gl_FragColor.r = step(uThresholdR, pixel.r);
		gl_FragColor.g = step(uThresholdG, pixel.g);
		gl_FragColor.b = step(uThresholdB, pixel.b);
		gl_FragColor.a = pixel.a;
	}

I happened to threshold each color channel separately but thresholding
typically done on a greyscale image.

### Posterize

Posterization reduces the number of colors in an image by quantizing
the r,g,b levels of each pixel. You can specify a number of bins (or 
how many levels) you would like each channel to be divided into. The
code is:

	uniform sampler2D tTexture;
	uniform float uBinsR;
	uniform float uBinsG;
	uniform float uBinsB;
	varying vec2 vUv;
	void main() {
		vec4 pixel = texture2D(tTexture, vUv);
		vec4 binSize = 255.0 / vec4( uBinsR, uBinsG, uBinsB, 1.0 );
		gl_FragColor = binSize * floor( 255.0 * pixel / binSize ) / 255.0;
	}

### TODO

 - Equalize?
 - Normalize?
 - Noise
   - Perlin
   - Simple

## Fragment Shaders - Multi Pixel

### Edge Detectors

#### Sobel

The Sobel edge detector highlights vertical and horizontal lines. It
has two "masks" or "kernels" which are used to emphasize horizontal or
vertical lines:

	Hor = [ [ -1 -2 -1 ]    Ver = [ [ -1 0 1 ]
	        [  0  0  0 ]            [ -2 0 2 ] 
	        [  1  2  1 ] ]          [ -1 0 1 ] ]

The shader code is given below:

	varying vec2 vUv;
	uniform sampler2D tTexture;
	uniform vec2 aspect;

	vec2 texel = vec2(1.0 / aspect.x, 1.0 / aspect.y);

	// Sobel convolution kernel(s)
	// There are 2 masks (or kernels) for the sobel operator
	mat3 K[2];
	const mat3 k0 = mat3( 1.0, 2.0, 1.0,   0.0, 0.0, 0.0,  -1.0, -2.0, -1.0 );
	const mat3 k1 = mat3( 1.0, 0.0, -1.0,  2.0, 0.0, -2.0,  1.0, 0.0, -1.0 );

	void main(){
		vec4 sample;

		// Matrix for storing the r,g,b pixels values in the texel
		mat3 R;
		mat3 G;
		mat3 B;

		// Arrays for storing mask[i]*sample[i]
		float r[2];
		float g[2];
		float b[2];

		// Sobel kernel
		K[0] = k0;
		K[1] = k1;

		// Store a 3x3 area of pixel values in R,G,B
		for (float i=0.0; i<3.0; i++) {
			for (float j=0.0; j<3.0; j++) {
				sample = texture2D( tTexture, vUv + texel * vec2(i-1.0,j-1.0) );
				R[int(i)][int(j)] = sample.r;
				G[int(i)][int(j)] = sample.g;
				B[int(i)][int(j)] = sample.b;
			}
		}

		// Calculate the convolution values for all the masks 
		for (int i=0; i<2; i++) {
			r[i] = pow(dot(K[i][0], R[0]) + dot(K[i][1], R[1]) + dot(K[i][2], R[2]), 2.0);
			g[i] = pow(dot(K[i][0], G[0]) + dot(K[i][1], G[1]) + dot(K[i][2], G[2]), 2.0);
			b[i] = pow(dot(K[i][0], B[0]) + dot(K[i][1], B[1]) + dot(K[i][2], B[2]), 2.0);
		}

		// Rescale the results
		gl_FragColor = vec4(
			0.5 * sqrt(r[0]*r[0]+r[1]*r[1]),
			0.5 * sqrt(g[0]*g[0]+g[1]*g[1]),
			0.5 * sqrt(b[0]*b[0]+b[1]*b[1]),
			1.0
		);
	}

